# Korean lexemes settings_dialog.py
lexemes = {
    # Settings dialog
    "tab_ondevice_llm_config": "기기 내 LLM",

    "module_ondevice_llm_config_label": "기기 내 LLM 모델",
    "module_ondevice_llm_config_path_label": "모델 위치",
    "module_ondevice_llm_config_path_input_placeholder_text": "모델 경로",
    "module_ondevice_llm_config_path_input_accessible_description": "모델 경로",

    "module_ondevice_llm_config_response_temperature_label": "온도: {temperature}",
    "module_ondevice_llm_config_response_temperature_input_accessible_description":
        "모델 출력의 무작위성을 조정합니다. 높은 값은 창의성을 증가시키고, 낮은 값은 결정론을 강화합니다.",

    "module_ondevice_llm_config_response_max_tokens_label": "최대 응답 토큰 수",
    "module_ondevice_llm_config_response_max_tokens_input_accessible_description":
        "응답에서 받을 수 있는 토큰의 최대 수, 예를 들어 단어와 구두점 등을 포함하여,"
        "출력의 길이를 제어합니다.",
}
