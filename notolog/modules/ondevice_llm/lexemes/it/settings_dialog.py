# Italian lexemes settings_dialog.py
lexemes = {
    # Settings dialog
    "tab_ondevice_llm_config": "LLM su dispositivo",

    "module_ondevice_llm_config_label": "Modello LLM su dispositivo",
    "module_ondevice_llm_config_path_label": "Posizione del modello",
    "module_ondevice_llm_config_path_input_placeholder_text": "Percorso del modello",
    "module_ondevice_llm_config_path_input_accessible_description": "Percorso del modello",

    "module_ondevice_llm_config_response_temperature_label": "Temperatura: {temperature}",
    "module_ondevice_llm_config_response_temperature_input_accessible_description":
        "Regola la casualità dell'output del modello. Valori più alti aumentano la creatività; "
        "valori più bassi aumentano il determinismo.",

    "module_ondevice_llm_config_response_max_tokens_label": "Numero massimo di token di risposta",
    "module_ondevice_llm_config_response_max_tokens_input_accessible_description":
        "Numero massimo di token da ricevere in risposta, come parole e punteggiatura, "
        "controllando la lunghezza dell'output.",
}
