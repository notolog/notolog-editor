# Japanese lexemes settings_dialog.py
lexemes = {
    # Settings dialog
    "tab_ondevice_llm_config": "デバイス上のLLM",

    "module_ondevice_llm_config_label": "デバイス上のLLMモデル",
    "module_ondevice_llm_config_path_label": "モデルの位置",
    "module_ondevice_llm_config_path_input_placeholder_text": "モデルのパス",
    "module_ondevice_llm_config_path_input_accessible_description": "モデルのパス",

    "module_ondevice_llm_config_response_temperature_label": "温度: {temperature}",
    "module_ondevice_llm_config_response_temperature_input_accessible_description":
        "モデル出力のランダム性を調整します。高い値は創造性を増加させ、低い値は決定論を強化します。",

    "module_ondevice_llm_config_response_max_tokens_label": "最大レスポンストークン数",
    "module_ondevice_llm_config_response_max_tokens_input_accessible_description":
        "レスポンスで受け取るトークンの最大数、例えば単語や句読点など、"
        "出力の長さを制御します。",
}
